"""
ğŸš“ Delegacia 5.0 â€” Dashboard de Risco Operacional para SeguranÃ§a Policial

Foco: ProteÃ§Ã£o e seguranÃ§a dos policiais em operaÃ§Ãµes de campo
- Alertas visuais de risco por zona/turno
- Mapas de calor de perigo operacional  
- RecomendaÃ§Ãµes tÃ¡ticas baseadas em ML
- MÃ©tricas de efetividade F1@20%
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
from sklearn.manifold import TSNE

warnings.filterwarnings('ignore')

# Importar utilitÃ¡rios
from utils.data_processor import DataProcessor
from utils.ml_models import RiskPredictor
from utils.visualizations import (
    create_risk_heatmap, create_geographic_risk_map, create_temporal_analysis,
    create_cluster_visualization, create_anomaly_visualization, create_pattern_network,
    create_elbow_plot, create_tsne_visualization, create_pca_scree_plot,
    create_association_rules_viz
)
from utils.risk_calculator import OfficerRiskCalculator
from utils.unsupervised_analysis import UnsupervisedRiskAnalyzer

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="ğŸš“ Delegacia 5.0 - Risco Operacional",
    page_icon="ğŸš“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS para indicadores de risco
st.markdown("""
<style>
.risk-high { 
    background-color: #FF4444; 
    color: white; 
    padding: 10px; 
    border-radius: 5px; 
    text-align: center;
    font-weight: bold;
}
.risk-medium { 
    background-color: #FFA500; 
    color: white; 
    padding: 10px; 
    border-radius: 5px; 
    text-align: center;
    font-weight: bold;
}
.risk-low { 
    background-color: #32CD32; 
    color: white; 
    padding: 10px; 
    border-radius: 5px; 
    text-align: center;
    font-weight: bold;
}
.metric-card {
    background-color: #f0f2f6;
    padding: 15px;
    border-radius: 10px;
    border-left: 5px solid #1f77b4;
}
</style>
""", unsafe_allow_html=True)

# TÃ­tulo principal
st.title("ğŸš“ Delegacia 5.0 â€” Dashboard de Risco Operacional")
st.markdown("**Foco na SeguranÃ§a do Policial:** Alertas, Mapas de Perigo e RecomendaÃ§Ãµes TÃ¡ticas")

# Sidebar para configuraÃ§Ãµes
st.sidebar.header("âš™ï¸ ConfiguraÃ§Ãµes")

# Inicializar processador de dados
@st.cache_data
def load_data():
    try:
        processor = DataProcessor("dataset_ocorrencias_delegacia_5.csv")
        return processor.get_processed_data()
    except Exception as e:
        st.error(f"Erro ao carregar dados: {str(e)}")
        return None

df = load_data()

if df is None:
    st.stop()

# Filtros na sidebar
st.sidebar.subheader("ğŸ” Filtros")

# Filtro de perÃ­odo
if 'data_ocorrencia' in df.columns:
    min_date = df['data_ocorrencia'].min().date()
    max_date = df['data_ocorrencia'].max().date()
    
    date_range = st.sidebar.date_input(
        "PerÃ­odo de AnÃ¡lise",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )
    
    if len(date_range) == 2:
        start_date, end_date = date_range
        df_filtered = df[
            (df['data_ocorrencia'].dt.date >= start_date) & 
            (df['data_ocorrencia'].dt.date <= end_date)
        ].copy()
    else:
        df_filtered = df.copy()
else:
    df_filtered = df.copy()

# Filtros adicionais
bairros = ['Todos'] + sorted(df_filtered['bairro'].unique().tolist())
selected_bairro = st.sidebar.selectbox("Bairro", bairros)

if selected_bairro != 'Todos':
    df_filtered = df_filtered[df_filtered['bairro'] == selected_bairro]

# Novo filtro: Tipo de Crime
if 'tipo_crime' in df_filtered.columns:
    crimes = ['Todos'] + sorted(df_filtered['tipo_crime'].unique().tolist())
    selected_crime = st.sidebar.selectbox("Tipo de Crime", crimes)
    
    if selected_crime != 'Todos':
        df_filtered = df_filtered[df_filtered['tipo_crime'] == selected_crime]

# Novo filtro: Arma Utilizada
if 'arma_utilizada' in df_filtered.columns:
    armas = ['Todas'] + sorted(df_filtered['arma_utilizada'].unique().tolist())
    selected_arma = st.sidebar.selectbox("Tipo de Arma", armas)
    
    if selected_arma != 'Todas':
        df_filtered = df_filtered[df_filtered['arma_utilizada'] == selected_arma]

# Inicializar calculador de risco
risk_calc = OfficerRiskCalculator()
risk_predictor = RiskPredictor()

# Treinar modelo
if len(df_filtered) > 100:
    risk_predictor.train_model(df_filtered)

# Calcular riscos
df_filtered = risk_calc.calculate_risk_scores(df_filtered)

# Tabs principais
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸš¨ Alertas de Risco",
    "ğŸ—ºï¸ Onde Patrulhar", 
    "â° AnÃ¡lise Temporal",
    "ğŸ“Š Fatores de Risco",
    "ğŸ“ˆ Efetividade Operacional",
    "ğŸ”¬ Descoberta de PadrÃµes"
])

# ================================
# TAB 1: ALERTAS DE RISCO
# ================================
with tab1:
    st.header("ğŸš¨ Sistema de Alertas de Risco Operacional")
    
    col1, col2, col3, col4 = st.columns(4)
    
    # MÃ©tricas principais
    total_ocorrencias = len(df_filtered)
    alto_risco = len(df_filtered[df_filtered['risco_alto'] == 1])
    taxa_risco = (alto_risco / total_ocorrencias * 100) if total_ocorrencias > 0 else 0
    
    with col1:
        st.metric("Total de OcorrÃªncias", f"{total_ocorrencias:,}")
    
    with col2:
        st.metric("SituaÃ§Ãµes de Alto Risco", f"{alto_risco:,}")
    
    with col3:
        st.metric("Taxa de Risco", f"{taxa_risco:.1f}%")
    
    with col4:
        # Status de alerta geral
        if taxa_risco >= 15:
            st.markdown('<div class="risk-high">âš ï¸ ALERTA MÃXIMO</div>', unsafe_allow_html=True)
        elif taxa_risco >= 10:
            st.markdown('<div class="risk-medium">ğŸŸ¡ ATENÃ‡ÃƒO</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="risk-low">ğŸŸ¢ SITUAÃ‡ÃƒO NORMAL</div>', unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Alertas por bairro
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ˜ï¸ Risco por Bairro (Ãšltimas 24h)")
        
        # Simular dados das Ãºltimas 24h (usar dados mais recentes)
        recent_data = df_filtered.tail(min(200, len(df_filtered)))
        bairro_risk = recent_data.groupby('bairro').agg({
            'risco_alto': ['count', 'sum', 'mean'],
            'risk_score': 'mean'
        }).round(2)
        
        bairro_risk.columns = ['Total', 'Alto_Risco', 'Taxa_Risco', 'Score_Medio']
        bairro_risk = bairro_risk.sort_values('Taxa_Risco', ascending=False)
        
        for bairro, row in bairro_risk.head(10).iterrows():
            taxa = row['Taxa_Risco'] * 100
            score = row['Score_Medio']
            
            if taxa >= 20:
                color_class = "risk-high"
                icon = "ğŸ”´"
            elif taxa >= 10:
                color_class = "risk-medium" 
                icon = "ğŸŸ¡"
            else:
                color_class = "risk-low"
                icon = "ğŸŸ¢"
            
            st.markdown(f"""
            <div class="{color_class}">
                {icon} <strong>{bairro}</strong><br>
                Taxa: {taxa:.1f}% | Score: {score:.2f}
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True)
    
    with col2:
        st.subheader("ğŸ• Risco por Turno Atual")
        
        # AnÃ¡lise por turno
        turno_risk = recent_data.groupby('turno').agg({
            'risco_alto': ['count', 'sum', 'mean'],
            'risk_score': 'mean'
        }).round(2)
        
        turno_risk.columns = ['Total', 'Alto_Risco', 'Taxa_Risco', 'Score_Medio']
        turno_risk = turno_risk.sort_values('Taxa_Risco', ascending=False)
        
        for turno, row in turno_risk.iterrows():
            taxa = row['Taxa_Risco'] * 100
            score = row['Score_Medio']
            
            if taxa >= 20:
                color_class = "risk-high"
                icon = "ğŸ”´"
            elif taxa >= 10:
                color_class = "risk-medium"
                icon = "ğŸŸ¡" 
            else:
                color_class = "risk-low"
                icon = "ğŸŸ¢"
            
            st.markdown(f"""
            <div class="{color_class}">
                {icon} <strong>{turno}</strong><br>
                Taxa: {taxa:.1f}% | Score: {score:.2f}
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True)

# ================================
# TAB 2: ONDE PATRULHAR
# ================================
with tab2:
    st.header("ğŸ—ºï¸ Mapa de Patrulhamento TÃ¡tico")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ”¥ Zonas de Alto Risco para Policiais")
        
        # Criar mapa de calor geogrÃ¡fico
        if 'latitude' in df_filtered.columns and 'longitude' in df_filtered.columns:
            fig_map = create_geographic_risk_map(df_filtered)
            st.plotly_chart(fig_map, use_container_width=True)
        else:
            st.info("Dados geogrÃ¡ficos nÃ£o disponÃ­veis")
    
    with col2:
        st.subheader("ğŸ›¡ï¸ RecomendaÃ§Ãµes TÃ¡ticas")
        
        # Top 5 bairros mais perigosos
        top_dangerous = df_filtered.groupby('bairro').agg({
            'risco_alto': 'mean',
            'arma_utilizada': lambda x: (x.isin(['Arma de Fogo', 'Explosivos'])).sum()
        }).sort_values('risco_alto', ascending=False).head(5)
        
        st.markdown("**ğŸ¯ Prioridade MÃ¡xima:**")
        for bairro, data in top_dangerous.iterrows():
            risk_pct = data['risco_alto'] * 100
            weapons = data['arma_utilizada']
            
            st.markdown(f"""
            <div class="metric-card">
                <strong>{bairro}</strong><br>
                Risco: {risk_pct:.1f}%<br>
                Armas: {weapons} casos<br>
                <em>ğŸ‘¥ Requer patrulha dupla</em>
            </div>
            """, unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True)
    
    st.markdown("---")
    
    # AnÃ¡lise de armas por bairro
    st.subheader("ğŸ”« DistribuiÃ§Ã£o de Armas por Zona")
    
    weapon_analysis = df_filtered.groupby(['bairro', 'arma_utilizada']).size().unstack(fill_value=0)
    
    if not weapon_analysis.empty:
        # Foco nas armas mais perigosas
        dangerous_weapons = ['Arma de Fogo', 'Explosivos']
        available_weapons = [w for w in dangerous_weapons if w in weapon_analysis.columns]
        
        if available_weapons:
            fig_weapons = px.bar(
                weapon_analysis[available_weapons].reset_index(),
                x='bairro',
                y=available_weapons,
                title="OcorrÃªncias com Armas Letais por Bairro",
                color_discrete_sequence=['#FF4444', '#FF8888'],
                height=400
            )
            fig_weapons.update_xaxes(tickangle=45)
            st.plotly_chart(fig_weapons, use_container_width=True)

# ================================
# TAB 3: ANÃLISE TEMPORAL
# ================================
with tab3:
    st.header("â° Quando os Policiais Correm Mais Risco?")
    
    # AnÃ¡lise por hora e dia da semana
    temporal_fig = create_temporal_analysis(df_filtered)
    st.plotly_chart(temporal_fig, use_container_width=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“… Risco por Dia da Semana")
        
        day_risk = df_filtered.groupby('dia_semana').agg({
            'risco_alto': ['count', 'sum', 'mean']
        })
        day_risk.columns = ['Total', 'Alto_Risco', 'Taxa_Risco']
        day_risk['Taxa_Risco_Pct'] = day_risk['Taxa_Risco'] * 100
        
        fig_days = px.bar(
            day_risk.reset_index(),
            x='dia_semana',
            y='Taxa_Risco_Pct',
            title="Taxa de Alto Risco por Dia da Semana (%)",
            color='Taxa_Risco_Pct',
            color_continuous_scale='Reds'
        )
        st.plotly_chart(fig_days, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ• Risco por Turno")
        
        shift_risk = df_filtered.groupby('turno').agg({
            'risco_alto': ['count', 'sum', 'mean'],
            'arma_utilizada': lambda x: (x.isin(['Arma de Fogo', 'Explosivos'])).sum()
        })
        shift_risk.columns = ['Total', 'Alto_Risco', 'Taxa_Risco', 'Armas_Letais']
        shift_risk['Taxa_Risco_Pct'] = shift_risk['Taxa_Risco'] * 100
        
        fig_shifts = px.pie(
            shift_risk.reset_index(),
            values='Armas_Letais',
            names='turno',
            title="DistribuiÃ§Ã£o de Armas Letais por Turno"
        )
        st.plotly_chart(fig_shifts, use_container_width=True)
    
    st.markdown("---")
    
    # MÃ©tricas operacionais por turno
    st.subheader("ğŸ“Š MÃ©tricas Operacionais por Turno")
    
    metrics_df = df_filtered.groupby('turno').agg({
        'risco_alto': ['count', 'sum', 'mean'],
        'quantidade_suspeitos': 'mean',
        'quantidade_vitimas': 'mean'
    }).round(2)
    
    metrics_df.columns = ['Total_Ocorrencias', 'Alto_Risco', 'Taxa_Risco', 'Media_Suspeitos', 'Media_Vitimas']
    metrics_df['Taxa_Risco_Pct'] = (metrics_df['Taxa_Risco'] * 100).round(1)
    
    st.dataframe(
        metrics_df[['Total_Ocorrencias', 'Alto_Risco', 'Taxa_Risco_Pct', 'Media_Suspeitos', 'Media_Vitimas']],
        use_container_width=True
    )

# ================================
# TAB 4: FATORES DE RISCO
# ================================
with tab4:
    st.header("ğŸ“Š O Que Torna Uma SituaÃ§Ã£o Mais Perigosa?")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ¯ Principais Fatores de Risco")
        
        # AnÃ¡lise de importÃ¢ncia das features
        if hasattr(risk_predictor, 'model') and risk_predictor.model is not None:
            try:
                feature_importance = risk_predictor.get_feature_importance()
                
                if not feature_importance.empty:
                    fig_importance = px.bar(
                        feature_importance.head(10),
                        x='importance',
                        y='feature',
                        orientation='h',
                        title="Top 10 Fatores que Aumentam o Risco ao Policial",
                        color='importance',
                        color_continuous_scale='Reds'
                    )
                    fig_importance.update_layout(height=500)
                    st.plotly_chart(fig_importance, use_container_width=True)
            except Exception as e:
                st.info("AnÃ¡lise de importÃ¢ncia indisponÃ­vel")
    
    with col2:
        st.subheader("ğŸ” AnÃ¡lise por Tipo de Crime")
        
        crime_risk = df_filtered.groupby('tipo_crime').agg({
            'risco_alto': ['count', 'sum', 'mean'],
            'quantidade_suspeitos': 'mean'
        }).round(2)
        
        crime_risk.columns = ['Total', 'Alto_Risco', 'Taxa_Risco', 'Media_Suspeitos']
        crime_risk['Taxa_Risco_Pct'] = crime_risk['Taxa_Risco'] * 100
        crime_risk = crime_risk.sort_values('Taxa_Risco', ascending=False)
        
        # Destacar os crimes mais perigosos
        st.markdown("**ğŸš¨ Crimes Mais Perigosos para Policiais:**")
        
        for crime, data in crime_risk.head(8).iterrows():
            taxa = data['Taxa_Risco_Pct']
            suspeitos = data['Media_Suspeitos']
            total = data['Total']
            
            if taxa >= 50:
                color = "ğŸ”´"
            elif taxa >= 25:
                color = "ğŸŸ¡"
            else:
                color = "ğŸŸ¢"
            
            st.markdown(f"""
            **{color} {crime}**  
            Taxa de Alto Risco: {taxa:.1f}%  
            MÃ©dia de Suspeitos: {suspeitos:.1f}  
            Total de Casos: {total}
            """)
            st.markdown("---")
    
    # Matriz de correlaÃ§Ã£o de fatores de risco
    st.subheader("ğŸ”— CorrelaÃ§Ã£o entre Fatores de Risco")
    
    numeric_cols = ['risco_alto', 'quantidade_suspeitos', 'quantidade_vitimas', 'hora', 'dia_semana_idx']
    available_cols = [col for col in numeric_cols if col in df_filtered.columns]
    
    if len(available_cols) > 2:
        corr_matrix = df_filtered[available_cols].corr()
        
        fig_corr = px.imshow(
            corr_matrix,
            title="CorrelaÃ§Ã£o entre VariÃ¡veis de Risco",
            color_continuous_scale='RdBu',
            aspect='auto'
        )
        st.plotly_chart(fig_corr, use_container_width=True)

# ================================
# TAB 5: EFETIVIDADE OPERACIONAL
# ================================
with tab5:
    st.header("ğŸ“ˆ Ganho Operacional com IA Preditiva")
    
    if hasattr(risk_predictor, 'model') and risk_predictor.model is not None:
        
        col1, col2, col3 = st.columns(3)
        
        # Calcular mÃ©tricas F1@20%
        try:
            f1_20_results = risk_predictor.calculate_f1_at_k(df_filtered, k=0.20)
            precision_20 = f1_20_results.get('precision', 0)
            recall_20 = f1_20_results.get('recall', 0)
            f1_20 = f1_20_results.get('f1_score', 0)
            
            with col1:
                st.metric(
                    "F1-Score @20%", 
                    f"{f1_20:.3f}",
                    help="Efetividade ao priorizar apenas 20% das ocorrÃªncias"
                )
            
            with col2:
                st.metric(
                    "PrecisÃ£o @20%",
                    f"{precision_20:.3f}",
                    help="% de situaÃ§Ãµes de alto risco identificadas corretamente"
                )
            
            with col3:
                st.metric(
                    "Recall @20%",
                    f"{recall_20:.3f}",
                    help="% do total de situaÃ§Ãµes de risco capturadas"
                )
        except Exception:
            st.info("MÃ©tricas de efetividade indisponÃ­veis")
        
        st.markdown("---")
        
        # SimulaÃ§Ã£o de ganho operacional
        st.subheader("ğŸ¯ SimulaÃ§Ã£o: Priorizando 20% das OcorrÃªncias")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **ğŸ“‹ CenÃ¡rio Atual (sem IA):**
            - Todas as ocorrÃªncias tratadas igualmente
            - Resposta reativa aos riscos
            - AlocaÃ§Ã£o uniforme de recursos
            """)
            
            # MÃ©tricas baseline
            total_casos = len(df_filtered)
            casos_alto_risco = len(df_filtered[df_filtered['risco_alto'] == 1])
            
            st.markdown(f"""
            **ğŸ“Š NÃºmeros Atuais:**
            - Total de casos: {total_casos:,}
            - Casos de alto risco: {casos_alto_risco:,}
            - Taxa de risco: {(casos_alto_risco/total_casos*100):.1f}%
            """)
        
        with col2:
            st.markdown("""
            **ğŸ¤– CenÃ¡rio com IA (F1@20%):**
            - Priorizacao inteligente das ocorrÃªncias
            - Foco nos 20% mais perigosos
            - OtimizaÃ§Ã£o de recursos policiais
            """)
            
            # Calcular benefÃ­cios
            casos_priorizados = int(total_casos * 0.20)
            casos_risco_capturados = int(casos_alto_risco * recall_20)
            
            st.markdown(f"""
            **ğŸ¯ Resultados Esperados:**
            - Casos priorizados: {casos_priorizados:,} (20%)
            - Alto risco capturado: {casos_risco_capturados:,}
            - EficiÃªncia: {(casos_risco_capturados/casos_priorizados*100):.1f}%
            """)
        
        # GrÃ¡fico de performance
        st.subheader("ğŸ“Š Curva de Performance do Modelo")
        
        if len(df_filtered) > 50:
            try:
                performance_data = risk_predictor.get_performance_curve(df_filtered)
                
                fig_perf = go.Figure()
                
                fig_perf.add_trace(go.Scatter(
                    x=performance_data['k_values'],
                    y=performance_data['precision'],
                    mode='lines+markers',
                    name='PrecisÃ£o',
                    line=dict(color='blue')
                ))
                
                fig_perf.add_trace(go.Scatter(
                    x=performance_data['k_values'],
                    y=performance_data['recall'],  # Aqui estava o erro
                    mode='lines+markers',
                    name='Recall',
                    line=dict(color='red')
                ))
                
                fig_perf.add_trace(go.Scatter(
                    x=performance_data['k_values'],
                    y=performance_data['f1_score'],
                    mode='lines+markers',
                    name='F1-Score',
                    line=dict(color='green')
                ))
                
                fig_perf.add_vline(x=20, line_dash="dash", line_color="orange",
                                  annotation_text="F1@20%")
                
                fig_perf.update_layout(
                    title="Performance do Modelo por % de OcorrÃªncias Priorizadas",
                    xaxis_title="% de OcorrÃªncias Priorizadas",
                    yaxis_title="Score",
                    hovermode='x unified'
                )
                
                st.plotly_chart(fig_perf, use_container_width=True)
                
            except Exception as e:
                st.info("GrÃ¡fico de performance indisponÃ­vel")
    
    else:
        st.info("Modelo nÃ£o treinado. Dados insuficientes.")
    
    st.markdown("---")
    
    # RelatÃ³rio de InteligÃªncia Operacional
    st.subheader("ğŸ“‹ RelatÃ³rio de InteligÃªncia Operacional")
    
    with st.expander("ğŸ“Š RecomendaÃ§Ãµes AutomÃ¡ticas", expanded=True):
        
        # Top bairros de risco
        top_risk_bairros = df_filtered.groupby('bairro')['risco_alto'].mean().sort_values(ascending=False).head(3)
        
        st.markdown("**ğŸ¯ ReforÃ§o Policial Recomendado:**")
        for bairro, risk_rate in top_risk_bairros.items():
            st.markdown(f"â€¢ **{bairro}**: Taxa de risco {risk_rate*100:.1f}% - Requer patrulhamento reforÃ§ado")
        
        # HorÃ¡rios crÃ­ticos
        hour_risk = df_filtered.groupby('hora')['risco_alto'].mean().sort_values(ascending=False).head(3)
        
        st.markdown("**â° HorÃ¡rios CrÃ­ticos:**")
        for hour, risk_rate in hour_risk.items():
            st.markdown(f"â€¢ **{hour:02d}h**: Taxa de risco {risk_rate*100:.1f}% - Aumentar efetivo")
        
        # Tipos de crime perigosos
        crime_risk = df_filtered.groupby('tipo_crime')['risco_alto'].mean().sort_values(ascending=False).head(3)
        
        st.markdown("**ğŸš¨ Protocolos Especiais:**")
        for crime, risk_rate in crime_risk.items():
            if risk_rate > 0.3:  # Acima de 30% de risco
                st.markdown(f"â€¢ **{crime}**: Protocolo de alta seguranÃ§a - Backup obrigatÃ³rio")

# ================================
# TAB 6: ANÃLISE NÃƒO SUPERVISIONADA
# ================================
with tab6:
    st.header("ğŸ”¬ Descoberta de PadrÃµes Ocultos (AnÃ¡lise NÃ£o Supervisionada)")
    
    st.markdown("""
    Esta aba utiliza **Machine Learning NÃ£o Supervisionado** para descobrir padrÃµes que nÃ£o sÃ£o Ã³bvios:
    - **Clustering:** Grupos naturais de ocorrÃªncias similares
    - **DetecÃ§Ã£o de Anomalias:** SituaÃ§Ãµes atÃ­picas que fogem do padrÃ£o
    - **AssociaÃ§Ãµes:** CombinaÃ§Ãµes de fatores que elevam o risco
    """)
    
    # Verificar se hÃ¡ dados suficientes
    if len(df_filtered) < 50:
        st.warning("âš ï¸ Dados insuficientes para anÃ¡lise nÃ£o supervisionada. Ajuste os filtros.")
        st.stop()
    
    # Inicializar analisador nÃ£o supervisionado
    unsupervised = UnsupervisedRiskAnalyzer()
    
    # Subtabs expandidos
    subtab1, subtab2, subtab3, subtab4, subtab5 = st.tabs([
        "ğŸ¯ Clustering de Risco",
        "ğŸ“Š AnÃ¡lise PCA & t-SNE",
        "âš¡ DetecÃ§Ã£o de Anomalias",
        "ğŸ”— Regras de AssociaÃ§Ã£o",
        "ğŸ“ˆ PadrÃµes Combinados"
    ])
    
    # ---- SUBTAB 1: CLUSTERING ----
    with subtab1:
        st.subheader("ğŸ¯ Descoberta de Grupos de Risco")
        
        st.markdown("""
        **O que Ã©?** O algoritmo agrupa ocorrÃªncias similares sem saber quais sÃ£o "perigosas".  
        **Por quÃª?** Revela padrÃµes naturais que podem indicar novos tipos de risco operacional.
        """)
        
        # Passo 1: MÃ©todo do cotovelo para encontrar k Ã³timo
        with st.expander("ğŸ“ Passo 1: Determinar NÃºmero Ã“timo de Clusters (MÃ©todo do Cotovelo)", expanded=False):
            try:
                with st.spinner("Calculando nÃºmero Ã³timo de clusters..."):
                    elbow_results = unsupervised.find_optimal_clusters(df_filtered, max_clusters=8)
                
                st.info(f"ğŸ’¡ **NÃºmero Ã³timo sugerido:** {elbow_results['optimal_k']} clusters (baseado na curvatura da inÃ©rcia)")
                st.info(f"ğŸ’¡ **Melhor Silhouette Score:** k = {elbow_results['best_silhouette_k']}")
                
                # VisualizaÃ§Ã£o do mÃ©todo do cotovelo
                fig_elbow = create_elbow_plot(elbow_results)
                st.plotly_chart(fig_elbow, use_container_width=True)
                
            except Exception as e:
                st.warning(f"MÃ©todo do cotovelo indisponÃ­vel: {str(e)}")
        
        st.markdown("---")
        
        # Passo 2: Executar clustering
        st.subheader("ğŸ“Š Passo 2: Executar Clustering")
        
        # Controles
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            cluster_method = st.selectbox("MÃ©todo de Clustering", ["K-Means", "DBSCAN"], index=0)
        with col2:
            if cluster_method == "K-Means":
                n_clusters = st.slider("NÃºmero de Clusters", min_value=2, max_value=8, value=4)
            else:
                st.info("DBSCAN encontra clusters automaticamente")
        
        try:
            method_param = 'kmeans' if cluster_method == "K-Means" else 'dbscan'
            
            with st.spinner(f"Executando {cluster_method} clustering..."):
                if method_param == 'kmeans':
                    clustering_results = unsupervised.perform_clustering(df_filtered, n_clusters=n_clusters, method='kmeans')
                else:
                    clustering_results = unsupervised.perform_clustering(df_filtered, method='dbscan')
            
            # MÃ©tricas de qualidade
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "Silhouette Score",
                    f"{clustering_results['silhouette_score']:.3f}",
                    help="Qualidade do clustering (0-1, maior = melhor)"
                )
            
            with col2:
                st.metric(
                    "Clusters Encontrados",
                    clustering_results['n_clusters']
                )
            
            with col3:
                st.metric(
                    "VariÃ¢ncia Explicada (PCA)",
                    f"{clustering_results['pca_variance_explained']*100:.1f}%",
                    help="% da variaÃ§Ã£o dos dados capturada em 2D"
                )
            
            st.markdown("---")
            
            # VisualizaÃ§Ã£o dos clusters
            st.subheader("ğŸ“Š VisualizaÃ§Ã£o dos Clusters (PCA)")
            fig_clusters = create_cluster_visualization(
                clustering_results['df_clustered'],
                clustering_results['cluster_stats']
            )
            st.plotly_chart(fig_clusters, use_container_width=True)
            
            st.markdown("---")
            
            # InterpretaÃ§Ã£o dos clusters
            st.subheader("ğŸ” InterpretaÃ§Ã£o dos Clusters")
            
            cluster_interpretations = unsupervised.get_cluster_interpretation(
                clustering_results['cluster_stats']
            )
            
            for interp in cluster_interpretations:
                with st.expander(f"{interp['profile']} - Cluster {interp['cluster_id']}", expanded=True):
                    st.markdown(f"**DescriÃ§Ã£o:** {interp['description']}")
                    st.markdown(f"**RecomendaÃ§Ã£o:** {interp['recommendation']}")
                    
                    st.markdown("**CaracterÃ­sticas TÃ­picas:**")
                    chars = interp['characteristics']
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown(f"- Crime mais comum: **{chars['crime_comum']}**")
                        st.markdown(f"- Bairro mais comum: **{chars['bairro_comum']}**")
                    with col2:
                        st.markdown(f"- Turno mais comum: **{chars['turno_comum']}**")
                        st.markdown(f"- Tamanho: **{chars['tamanho']}**")
            
            # EstatÃ­sticas detalhadas
            st.markdown("---")
            st.subheader("ğŸ“‹ EstatÃ­sticas Detalhadas por Cluster")
            
            stats_display = clustering_results['cluster_stats'].copy()
            stats_display['high_risk_rate'] = (stats_display['high_risk_rate'] * 100).round(1)
            stats_display['weapon_rate'] = (stats_display['weapon_rate'] * 100).round(1)
            stats_display['percentage'] = stats_display['percentage'].round(1)
            
            st.dataframe(
                stats_display[[
                    'cluster_id', 'size', 'percentage', 'high_risk_rate', 
                    'weapon_rate', 'avg_suspects', 'most_common_crime'
                ]].rename(columns={
                    'cluster_id': 'Cluster',
                    'size': 'Tamanho',
                    'percentage': '% do Total',
                    'high_risk_rate': 'Taxa Alto Risco (%)',
                    'weapon_rate': 'Taxa Arma Letal (%)',
                    'avg_suspects': 'MÃ©dia Suspeitos',
                    'most_common_crime': 'Crime Mais Comum'
                }),
                use_container_width=True
            )
            
        except Exception as e:
            st.error(f"Erro no clustering: {str(e)}")
    
    # ---- SUBTAB 2: ANÃLISE PCA & t-SNE ----
    with subtab2:
        st.subheader("ğŸ“Š ReduÃ§Ã£o Dimensional e VisualizaÃ§Ã£o AvanÃ§ada")
        
        st.markdown("""
        **O que Ã©?** TÃ©cnicas para reduzir dados multidimensionais em 2D, mantendo informaÃ§Ãµes importantes.  
        **Por quÃª?** Permite visualizar padrÃµes complexos de forma intuitiva.
        """)
        
        # PCA Completo
        st.markdown("### ğŸ”¬ AnÃ¡lise de Componentes Principais (PCA)")
        
        try:
            with st.spinner("Executando anÃ¡lise PCA completa..."):
                pca_results = unsupervised.perform_pca_analysis(df_filtered)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    "Componentes para 90% de VariÃ¢ncia",
                    pca_results['n_components_90'],
                    help="NÃºmero de componentes necessÃ¡rios para capturar 90% da variaÃ§Ã£o dos dados"
                )
            
            with col2:
                st.metric(
                    "Total de Componentes",
                    pca_results['n_components']
                )
            
            # Scree plot
            st.markdown("#### ğŸ“ˆ Scree Plot: VariÃ¢ncia Explicada por Componente")
            fig_scree = create_pca_scree_plot(pca_results)
            st.plotly_chart(fig_scree, use_container_width=True)
            
            # Loadings (contribuiÃ§Ã£o das features)
            with st.expander("ğŸ“‹ ContribuiÃ§Ã£o das Features (Loadings)", expanded=False):
                st.markdown("**As features mais importantes em cada componente principal:**")
                
                # Mostrar top 3 componentes
                loadings_display = pca_results['loadings'].iloc[:, :min(3, pca_results['n_components'])]
                loadings_display = loadings_display.round(3)
                st.dataframe(loadings_display, use_container_width=True)
                
                st.info("""
                **Como interpretar:**
                - Valores positivos altos: Feature contribui positivamente para o componente
                - Valores negativos altos: Feature contribui negativamente
                - Valores prÃ³ximos de 0: Feature tem pouca contribuiÃ§Ã£o
                """)
            
        except Exception as e:
            st.warning(f"AnÃ¡lise PCA indisponÃ­vel: {str(e)}")
        
        st.markdown("---")
        
        # t-SNE
        st.markdown("### ğŸ¨ VisualizaÃ§Ã£o t-SNE")
        
        st.markdown("""
        **t-SNE** (t-Distributed Stochastic Neighbor Embedding) Ã© uma tÃ©cnica alternativa ao PCA 
        que frequentemente revela padrÃµes locais e clusters de forma mais clara.
        """)
        
        col1, col2 = st.columns([3, 1])
        with col2:
            perplexity = st.slider("Perplexity", min_value=5, max_value=50, value=30, 
                                  help="Controla o balanÃ§o entre estrutura local e global")
        
        try:
            with st.spinner("Calculando t-SNE (pode levar alguns segundos)..."):
                tsne_results = unsupervised.perform_tsne(df_filtered, perplexity=perplexity)
            
            st.success(f"âœ… t-SNE executado com perplexity = {tsne_results['perplexity_used']}")
            
            # VisualizaÃ§Ã£o t-SNE
            fig_tsne = create_tsne_visualization(tsne_results['df_tsne'])
            st.plotly_chart(fig_tsne, use_container_width=True)
            
            st.info("""
            **ğŸ’¡ Dica:** No t-SNE, pontos prÃ³ximos indicam ocorrÃªncias similares. 
            Procure por:
            - **Clusters separados**: Grupos distintos de risco
            - **Gradientes de cor**: TransiÃ§Ãµes de baixo para alto risco
            - **Outliers**: Pontos isolados (potenciais anomalias)
            """)
            
        except Exception as e:
            st.warning(f"t-SNE indisponÃ­vel: {str(e)}")
    
    # ---- SUBTAB 3: ANOMALIAS ----
    with subtab3:
        st.subheader("âš¡ DetecÃ§Ã£o de OcorrÃªncias AnÃ´malas")
        
        st.markdown("""
        **O que Ã©?** Identifica ocorrÃªncias que "nÃ£o se encaixam" no padrÃ£o normal.  
        **Por quÃª?** Anomalias podem ser situaÃ§Ãµes raras mas extremamente perigosas, ou indicar mudanÃ§as no perfil criminal.
        """)
        
        # Controle de sensibilidade
        col1, col2 = st.columns([3, 1])
        with col2:
            contamination = st.slider(
                "Sensibilidade (%)",
                min_value=5,
                max_value=20,
                value=10,
                help="% de ocorrÃªncias esperadas como anÃ´malas"
            ) / 100
        
        try:
            with st.spinner("Detectando anomalias com Isolation Forest..."):
                anomaly_results = unsupervised.detect_anomalies(df_filtered, contamination=contamination)
            
            # MÃ©tricas
            col1, col2, col3 = st.columns(3)
            
            stats = anomaly_results['stats']
            
            with col1:
                st.metric(
                    "Anomalias Detectadas",
                    stats['total_anomalies'],
                    f"{stats['anomaly_percentage']:.1f}% do total"
                )
            
            with col2:
                st.metric(
                    "Taxa de Risco (Anomalias)",
                    f"{stats['anomalies_high_risk_rate']*100:.1f}%",
                    help="% de anomalias que sÃ£o alto risco"
                )
            
            with col3:
                st.metric(
                    "Taxa de Risco (Normais)",
                    f"{stats['normal_high_risk_rate']*100:.1f}%",
                    help="% de ocorrÃªncias normais que sÃ£o alto risco"
                )
            
            # ComparaÃ§Ã£o
            if stats['anomalies_high_risk_rate'] > stats['normal_high_risk_rate']:
                diff = (stats['anomalies_high_risk_rate'] - stats['normal_high_risk_rate']) * 100
                st.info(f"âœ… **Insight:** Anomalias tÃªm {diff:.1f}% mais chance de serem alto risco que ocorrÃªncias normais!")
            
            st.markdown("---")
            
            # VisualizaÃ§Ã£o
            st.subheader("ğŸ“Š DistribuiÃ§Ã£o de Scores de Anomalia")
            fig_anomalies = create_anomaly_visualization(anomaly_results['df_anomalies'])
            st.plotly_chart(fig_anomalies, use_container_width=True)
            
            st.markdown("---")
            
            # Top anomalias
            st.subheader("ğŸ”¥ Top 10 OcorrÃªncias Mais AnÃ´malas")
            
            top_anomalies = anomaly_results['top_anomalies'].head(10)
            
            for idx, (_, row) in enumerate(top_anomalies.iterrows(), 1):
                with st.expander(f"#{idx} - Anomalia Score: {row['anomaly_score']:.3f}", expanded=(idx <= 3)):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown(f"**Bairro:** {row.get('bairro', 'N/A')}")
                        st.markdown(f"**Crime:** {row.get('tipo_crime', 'N/A')}")
                        st.markdown(f"**Arma:** {row.get('arma_utilizada', 'N/A')}")
                    
                    with col2:
                        st.markdown(f"**Turno:** {row.get('turno', 'N/A')}")
                        st.markdown(f"**Suspeitos:** {row.get('quantidade_suspeitos', 'N/A')}")
                        st.markdown(f"**VÃ­timas:** {row.get('quantidade_vitimas', 'N/A')}")
                    
                    if row.get('risco_alto', 0) == 1:
                        st.error("ğŸ”´ **ALTO RISCO CONFIRMADO**")
                    else:
                        st.warning("ğŸŸ¡ PadrÃ£o atÃ­pico - investigar")
            
            # AnÃ¡lise de locais
            if stats['top_anomaly_locations']:
                st.markdown("---")
                st.subheader("ğŸ“ Bairros com Mais Anomalias")
                
                locations_df = pd.DataFrame(
                    list(stats['top_anomaly_locations'].items()),
                    columns=['Bairro', 'NÃºmero de Anomalias']
                )
                
                fig_locations = px.bar(
                    locations_df,
                    x='Bairro',
                    y='NÃºmero de Anomalias',
                    title="DistribuiÃ§Ã£o GeogrÃ¡fica de Anomalias",
                    color='NÃºmero de Anomalias',
                    color_continuous_scale='Reds'
                )
                st.plotly_chart(fig_locations, use_container_width=True)
            
        except Exception as e:
            st.error(f"Erro na detecÃ§Ã£o de anomalias: {str(e)}")
    
    # ---- SUBTAB 4: REGRAS DE ASSOCIAÃ‡ÃƒO ----
    with subtab4:
        st.subheader("ğŸ”— MineraÃ§Ã£o de Regras de AssociaÃ§Ã£o (Apriori)")
        
        st.markdown("""
        **O que Ã©?** Algoritmo Apriori descobre regras do tipo "SE X E Y ENTÃƒO Z" em situaÃ§Ãµes de alto risco.  
        **Por quÃª?** Revela combinaÃ§Ãµes especÃ­ficas de fatores que elevam drasticamente o risco operacional.
        """)
        
        # Controles
        col1, col2 = st.columns(2)
        with col1:
            min_support = st.slider("Suporte MÃ­nimo (%)", min_value=1, max_value=20, value=5,
                                   help="FrequÃªncia mÃ­nima da combinaÃ§Ã£o") / 100
        with col2:
            min_confidence = st.slider("ConfianÃ§a MÃ­nima (%)", min_value=30, max_value=100, value=50,
                                      help="ForÃ§a da regra (probabilidade condicional)") / 100
        
        try:
            with st.spinner("Minerando regras de associaÃ§Ã£o com Apriori..."):
                association_results = unsupervised.find_association_rules(
                    df_filtered, 
                    min_support=min_support,
                    min_confidence=min_confidence
                )
            
            if association_results['total_rules'] == 0:
                st.info("âš ï¸ Nenhuma regra encontrada com esses parÃ¢metros. Tente reduzir o suporte ou confianÃ§a mÃ­nimos.")
            else:
                st.success(f"âœ… {association_results['total_rules']} regras de associaÃ§Ã£o descobertas!")
                
                # VisualizaÃ§Ã£o das regras
                st.markdown("### ğŸ“Š VisualizaÃ§Ã£o de Regras (Support Ã— Confidence Ã— Lift)")
                fig_rules = create_association_rules_viz(association_results['rules'])
                st.plotly_chart(fig_rules, use_container_width=True)
                
                st.markdown("---")
                
                # Top regras
                st.markdown("### ğŸ”¥ Top 10 Regras Mais Importantes (por Lift)")
                
                top_rules = association_results['rules'].nlargest(10, 'lift')
                
                for idx, (_, rule) in enumerate(top_rules.iterrows(), 1):
                    # Converter frozensets para strings legÃ­veis
                    antecedents = ', '.join([item.replace('_', ' ') for item in list(rule['antecedents'])])
                    consequents = ', '.join([item.replace('_', ' ') for item in list(rule['consequents'])])
                    
                    with st.expander(f"#{idx}: {antecedents} â†’ {consequents} (Lift: {rule['lift']:.2f})", expanded=(idx <= 3)):
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Suporte", f"{rule['support']:.1%}", 
                                     help="FrequÃªncia desta combinaÃ§Ã£o")
                        with col2:
                            st.metric("ConfianÃ§a", f"{rule['confidence']:.1%}",
                                     help="Probabilidade do consequente dado o antecedente")
                        with col3:
                            st.metric("Lift", f"{rule['lift']:.2f}",
                                     help=">1 significa correlaÃ§Ã£o positiva")
                        
                        st.markdown(f"""
                        **InterpretaÃ§Ã£o:**
                        - Quando ocorrem: **{antecedents}**
                        - HÃ¡ {rule['confidence']*100:.0f}% de chance de tambÃ©m ocorrer: **{consequents}**
                        - Esta combinaÃ§Ã£o Ã© {rule['lift']:.1f}x mais provÃ¡vel do que o acaso
                        """)
                        
                        if rule['lift'] > 2.0:
                            st.error("ğŸš¨ **REGRA CRÃTICA**: Lift muito alto indica forte associaÃ§Ã£o de risco!")
                
                # Tabela completa
                with st.expander("ğŸ“‹ Todas as Regras (Tabela Completa)", expanded=False):
                    rules_display = association_results['rules'].copy()
                    rules_display['antecedents'] = rules_display['antecedents'].apply(
                        lambda x: ', '.join([item.replace('_', ' ') for item in list(x)])
                    )
                    rules_display['consequents'] = rules_display['consequents'].apply(
                        lambda x: ', '.join([item.replace('_', ' ') for item in list(x)])
                    )
                    
                    st.dataframe(
                        rules_display[['antecedents', 'consequents', 'support', 'confidence', 'lift']],
                        use_container_width=True
                    )
                
        except Exception as e:
            st.warning(f"Regras de associaÃ§Ã£o indisponÃ­veis: {str(e)}")
    
    # ---- SUBTAB 5: PADRÃ•ES COMBINADOS ----
    with subtab5:
        st.subheader("ğŸ“ˆ PadrÃµes Combinados (AnÃ¡lise ClÃ¡ssica)")
        
        st.markdown("""
        **AnÃ¡lise de padrÃµes usando agregaÃ§Ãµes estatÃ­sticas** para complementar os algoritmos avanÃ§ados.
        """)
        
        try:
            with st.spinner("Minerando padrÃµes de associaÃ§Ã£o..."):
                patterns = unsupervised.find_risk_patterns(df_filtered)
            
            if patterns['total_patterns_found'] == 0:
                st.info("Nenhum padrÃ£o significativo encontrado com os filtros atuais.")
            else:
                st.success(f"âœ… {patterns['total_patterns_found']} tipo(s) de padrÃ£o descoberto(s)!")
                
                # Exibir cada padrÃ£o
                for idx, pattern in enumerate(patterns['patterns']):
                    st.markdown(f"### {pattern['type']}")
                    st.markdown(f"*{pattern['description']}*")
                    fig_pattern = create_pattern_network(patterns)
                    st.plotly_chart(fig_pattern, use_container_width=True, key=f"pattern_{idx}")
                    with st.expander("ğŸ“‹ Ver Dados Detalhados"):
                        st.dataframe(pattern['data'], use_container_width=True)
                    st.markdown("---")
                
                # Insights prÃ¡ticos
                st.subheader("ğŸ’¡ Insights para OperaÃ§Ãµes")
                
                st.markdown("""
                **Como usar esses padrÃµes:**
                
                1. **PriorizaÃ§Ã£o de Patrulhamento:** Focar nos locais/horÃ¡rios dos padrÃµes de alto risco
                2. **AlocaÃ§Ã£o de Recursos:** Quando detectar padrÃ£o crÃ­tico, enviar backup preventivo
                3. **Treinamento:** Preparar equipes para situaÃ§Ãµes tÃ­picas de cada padrÃ£o
                4. **PrevenÃ§Ã£o:** Identificar padrÃµes emergentes antes que se tornem tendÃªncia
                """)
                
        except Exception as e:
            st.error(f"Erro na anÃ¡lise de padrÃµes: {str(e)}")
    
    # Resumo geral
    st.markdown("---")
    st.info("""
    **ğŸ“ DiferenÃ§a entre AnÃ¡lise Supervisionada e NÃ£o Supervisionada:**
    
    - **Supervisionada (Tabs anteriores):** "Aprende" o que vocÃª definiu como risco (arma de fogo/explosivos) e prevÃª ocorrÃªncias futuras
    - **NÃ£o Supervisionada (Esta tab):** "Descobre" padrÃµes escondidos que vocÃª talvez nÃ£o sabia que existiam
    
    **Complementaridade:** Use ambas! A supervisionada prevÃª, a nÃ£o supervisionada descobre novos riscos.
    """)

# Footer
st.markdown("---")
st.markdown("**ğŸš“ Delegacia 5.0** - Sistema de InteligÃªncia para SeguranÃ§a Policial")
st.markdown("*Protegendo quem nos protege atravÃ©s de dados e IA*")
